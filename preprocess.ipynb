{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186f98a-f9bc-4c5c-92fb-75cc7fcd8eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/MeloTTS/melo')\n",
    "sys.path.append('/workspace/MeloTTS/melo/text')\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "\n",
    "from melo.text.ca_phonemizer import cleaner as ca_cleaner\n",
    "from melo.text.ca_phonemizer import ca_to_ipa\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from melo.text.cleaner import clean_text_bert\n",
    "import os\n",
    "import torch\n",
    "from melo.text.symbols import symbols, num_languages, num_tones\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from random import shuffle\n",
    "from typing import Optional\n",
    "\n",
    "import click\n",
    "\n",
    "val_per_spk = 4\n",
    "max_val_total = 8\n",
    "\n",
    "base_dir = \"/workspace/MeloTTS/melo\"\n",
    "metadata = \"/workspace/MeloTTS/melo/datasets/balear/metadata.list\"\n",
    "train_path = os.path.join(os.path.dirname(metadata), 'train.list')\n",
    "val_path = os.path.join(os.path.dirname(metadata), 'val.list')\n",
    "out_config_path = os.path.join(os.path.dirname(metadata), 'config.json')\n",
    "cleaned_path = metadata + \".cleaned\"\n",
    "out_file = open(cleaned_path, \"w\", encoding=\"utf-8\")\n",
    "new_symbols = []\n",
    "#i = 0\n",
    "for line in tqdm(open(metadata, encoding=\"utf-8\").readlines()):\n",
    "    #print(i)\n",
    "    #i+=1\n",
    "    try:\n",
    "        utt, spk, language, text = line.strip().split(\"|\")\n",
    "        #print(utt, spk, language, text)\n",
    "        norm_text, phones, tones, word2ph, bert = clean_text_bert(text, language, device='cuda:0')\n",
    "        #print(norm_text, phones, tones, word2ph, bert)\n",
    "        for ph in phones:\n",
    "            if ph not in symbols and ph not in new_symbols:\n",
    "                new_symbols.append(ph)\n",
    "                print('update!, now symbols:')\n",
    "                print(new_symbols)\n",
    "                with open(f'{language}_symbol.txt', 'w') as f:\n",
    "                    f.write(f'{new_symbols}')\n",
    "\n",
    "        assert len(phones) == len(tones)\n",
    "        assert len(phones) == sum(word2ph)\n",
    "        out_file.write(\n",
    "            \"{}|{}|{}|{}|{}|{}|{}\\n\".format(\n",
    "                utt,\n",
    "                spk,\n",
    "                language,\n",
    "                norm_text,\n",
    "                \" \".join(phones),\n",
    "                \" \".join([str(i) for i in tones]),\n",
    "                \" \".join([str(i) for i in word2ph]),\n",
    "            )\n",
    "        )\n",
    "        #print(\"k\")\n",
    "        bert_path = utt.replace(\".wav\", \".bert.pt\")\n",
    "        #os.makedirs(os.path.dirname(bert_path), exist_ok=True)\n",
    "        #print(bert_path)\n",
    "        \n",
    "        torch.save(bert.cpu(), os.path.join(base_dir,bert_path))\n",
    "        #print(\"ok\")\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        print(\"err!\", line, error)\n",
    "\n",
    "out_file.close()\n",
    "\n",
    "metadata = cleaned_path\n",
    "\n",
    "spk_utt_map = defaultdict(list)\n",
    "spk_id_map = {}\n",
    "current_sid = 0\n",
    "\n",
    "with open(metadata, encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        utt, spk, language, text, phones, tones, word2ph = line.strip().split(\"|\")\n",
    "        spk_utt_map[spk].append(line)\n",
    "\n",
    "        if spk not in spk_id_map.keys():\n",
    "            spk_id_map[spk] = current_sid\n",
    "            current_sid += 1\n",
    "\n",
    "train_list = []\n",
    "val_list = []\n",
    "\n",
    "for spk, utts in spk_utt_map.items():\n",
    "    shuffle(utts)\n",
    "    val_list += utts[:val_per_spk]\n",
    "    train_list += utts[val_per_spk:]\n",
    "\n",
    "if len(val_list) > max_val_total:\n",
    "    train_list += val_list[max_val_total:]\n",
    "    val_list = val_list[:max_val_total]\n",
    "\n",
    "with open(train_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in train_list:\n",
    "        f.write(line)\n",
    "\n",
    "with open(val_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in val_list:\n",
    "        f.write(line)\n",
    "\n",
    "config = json.load(open(config_path, encoding=\"utf-8\"))\n",
    "config[\"data\"][\"spk2id\"] = spk_id_map\n",
    "\n",
    "config[\"data\"][\"training_files\"] = train_path\n",
    "config[\"data\"][\"validation_files\"] = val_path\n",
    "config[\"data\"][\"n_speakers\"] = len(spk_id_map)\n",
    "config[\"num_languages\"] = num_languages\n",
    "config[\"num_tones\"] = num_tones\n",
    "config[\"symbols\"] = symbols\n",
    "\n",
    "with open(out_config_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config, f, indent=2, ensure_ascii=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
